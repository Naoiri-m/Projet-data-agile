{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe les librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo-oncfm.png'  width=360px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détectez des faux billets avec Python<br>Algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> &#9888; Ce *notebook* contient l'algorithme retenu pour la détection des faux billets. Le travail de préparation et de sélection du modèle est présenté dans le fichier `detection-faux-billets-oncfm-preparation-donnees.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommaire\n",
    "* [Importation du modèle](#1)\n",
    "* [Choix du fichier à analyser](#2)\n",
    "* [Vérification des données et détection](#3)\n",
    "* [Affichage des résultats](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation du modèle<a id='1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle effectué avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Définit le modèle à importer et son chemin\n",
    "model_folder = Path.cwd() / 'modele'\n",
    "model_file = 'logistic-regression-gs.joblib'\n",
    "model_path = Path(model_folder / model_file)\n",
    "\n",
    "# Charge le modèle si le fichier 'joblib' est présent au bon emplacement\n",
    "if not model_folder.is_dir():\n",
    "    raise FileNotFoundError(\n",
    "        f'Impossible de charger le modèle : le dossier \\'{model_folder}\\''\n",
    "        f' n\\'existe pas.'\n",
    "    )\n",
    "elif not model_path.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        f'Impossible de charger le modèle : le fichier \\'{model_file}\\''\n",
    "        f' est manquant.'\n",
    "    )\n",
    "else:\n",
    "    clf = joblib.load(model_path)\n",
    "    print('Chargement du modèle effectué avec succès.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix du fichier à analyser<a id='2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers disponibles pour le test :\n",
      "0 | billets-production-missing-feature.csv\n",
      "1 | billets-production-no-fake.csv\n",
      "2 | billets-production-test-nan.csv\n",
      "3 | billets-production-v2.csv\n",
      "4 | billets-production.csv\n",
      "\n",
      "Vous avez choisi le fichier 'billets-production.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Initialise le chemin du dossier contenant les fichiers à tester\n",
    "data_folder = Path.cwd() / 'datasets'\n",
    "\n",
    "# Initialise l'indice du fichier sélectionné\n",
    "j=-1\n",
    "\n",
    "# Vérifie la présence du dossier 'datasets', liste les fichiers CSV qu'il\n",
    "# contient et récupère le choix utilisateur\n",
    "if not data_folder.is_dir():\n",
    "    raise FileNotFoundError(f'Le dossier {data_folder} n\\'existe pas.')\n",
    "else:\n",
    "    csv_files = [x for x in list(data_folder.glob('*.csv')) if x.is_file()]\n",
    "    if len(csv_files) != 0:\n",
    "        print('Fichiers disponibles pour le test :')\n",
    "        for i, file in enumerate(csv_files):\n",
    "            print(f'{i} | {file.parts[-1]}')\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            'Il n\\'y a pas de fichiers CSV à tester dans votre dossier.')\n",
    "    \n",
    "    while j not in range(0, len(csv_files)):\n",
    "        j = int(input('Indiquez le numéro du fichier à tester.'))\n",
    "\n",
    "print(f'\\nVous avez choisi le fichier \\'{csv_files[j].parts[-1]}\\'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification des données et détection<a id='3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise le set des colonnes que doit contenir le fichier à tester\n",
    "features = {'diagonal', 'height_left', 'height_right', 'margin_low',\n",
    "            'margin_up', 'length', 'id'}\n",
    "\n",
    "# Importe le fichier CSV dans un DataFrame\n",
    "df = pd.read_csv(csv_files[j])\n",
    "\n",
    "# Crée un set avec le nom des colonnes du DataFrame\n",
    "df_features = set(df.columns)\n",
    "\n",
    "# Vérifie que les features nécessaires sont présentes\n",
    "if len(features - df_features) != 0:\n",
    "    raise Exception(\n",
    "        f'Impossible de tester le fichier, les variables suivantes sont '\n",
    "        f'manquantes : {list(features - df_features)}')\n",
    "\n",
    "# Vérifie qu'il n'y a pas de valeurs manquantes.\n",
    "elif df.isna().any().any():\n",
    "    raise Exception(\n",
    "        f'Impossible de tester le fichier, les variables suivantes ont '\n",
    "        f'des valeurs manquantes : {df.columns[df.isna().any()].to_list()}')\n",
    "\n",
    "# Effectue la prédiction\n",
    "else:\n",
    "    ids = df['id']\n",
    "    X = df.drop(columns='id')\n",
    "    y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des résultats<a id='4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id des faux billets détectés : ['A_1', 'A_2', 'A_3']\n",
      "\n",
      "Détails de la détection :\n",
      "\n",
      "    id  is_fake  probability_estimates\n",
      "0  A_1     True               0.999787\n",
      "1  A_2     True               0.999977\n",
      "2  A_3     True               0.999969\n",
      "3  A_4    False               0.976606\n",
      "4  A_5    False               0.999984\n"
     ]
    }
   ],
   "source": [
    "# Crée un DataFrame contenant les résultats de la prédiction\n",
    "df_results = pd.DataFrame(\n",
    "    zip(ids, y_pred, clf.predict_proba(X)[:, 0], clf.predict_proba(X)[:, 1]),\n",
    "    columns=['id', 'is_fake', 'prob_0', 'prob_1']\n",
    ")\n",
    "df_results['is_fake'] = df_results['is_fake'].map({0: False, 1: True})\n",
    "\n",
    "df_results['probability_estimates'] = np.where(\n",
    "    df_results['is_fake'], df_results['prob_1'], df_results['prob_0'])\n",
    "\n",
    "df_results = df_results.drop(columns=['prob_0', 'prob_1'])\n",
    "\n",
    "# Affiche les résultats de la détection\n",
    "fake_banknote_list = list(df_results.loc[df_results['is_fake'] == True, 'id'])\n",
    "\n",
    "if len(fake_banknote_list) == 0:\n",
    "    print('Aucun faux billet n\\'a été détecté.')\n",
    "else:\n",
    "    print(f'Id des faux billets détectés : {fake_banknote_list}\\n')\n",
    "    print('Détails de la détection :\\n')\n",
    "    print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
